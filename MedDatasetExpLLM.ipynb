{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Keshvii/MedMCQA_Exp/blob/main/MedDatasetExpLLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyQyUrZYvc61"
      },
      "source": [
        "# LLMS ACCURACY CHECK"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJHV0dCHnCCF",
        "outputId": "8be21237-0dde-421d-b2a0-8d7d7cf652f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNHihQM2vcP_",
        "outputId": "43e8a0ee-3401-4795-e45f-39e53fa972dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.87.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KYYPTvk8_mq"
      },
      "source": [
        "# GROQ"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zero-Shot Prompt: llama3-70b-8192(Acc=68.6)"
      ],
      "metadata": {
        "id": "M50gMQOWlIpH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552,
          "referenced_widgets": [
            "53476cb945924e2f9fdda881b7294965",
            "b7c0fd4ac887440aa99e983799052456",
            "8083435822814d138c8d6699971c5db4",
            "c3bd4cc7c7dc4886ac39168bbfc153af",
            "ed3588f44cd64507ae3a4d26b75eaedd",
            "b477f2f9cf1345a2bfbd426ebbcc7b23",
            "1c3f97440f8241378217fdfe29030640",
            "febf900974f94d27a94af665bb5206a0",
            "468755e6e63e44689a90452fcc50d3da",
            "5b2ef5750ef7472bbdc19bc298db8627",
            "39d833c265044a1bb28b28581462dd23"
          ]
        },
        "id": "GP5fg0e18-0F",
        "outputId": "7f908467-cf80-49af-a5b8-c6e62bfcb338"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4183 entries, 0 to 4182\n",
            "Data columns (total 11 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   id            4183 non-null   object\n",
            " 1   question      4183 non-null   object\n",
            " 2   opa           4183 non-null   object\n",
            " 3   opb           4183 non-null   object\n",
            " 4   opc           4182 non-null   object\n",
            " 5   opd           4143 non-null   object\n",
            " 6   cop           4183 non-null   int64 \n",
            " 7   choice_type   4183 non-null   object\n",
            " 8   exp           2206 non-null   object\n",
            " 9   subject_name  4183 non-null   object\n",
            " 10  topic_name    423 non-null    object\n",
            "dtypes: int64(1), object(10)\n",
            "memory usage: 359.6+ KB\n",
            "\n",
            "--- Evaluating llama3-70b-8192 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "llama3-70b-8192 Progress:   0%|          | 0/419 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "53476cb945924e2f9fdda881b7294965"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in batch 118 for model llama3-70b-8192: Connection error.\n",
            "Error in batch 197 for model llama3-70b-8192: no healthy upstream\n",
            "Error in batch 198 for model llama3-70b-8192: no healthy upstream\n",
            "Error in batch 238 for model llama3-70b-8192: no healthy upstream\n",
            "Error in batch 239 for model llama3-70b-8192: no healthy upstream\n",
            "Accuracy for llama3-70b-8192: 0.686 (2836/4133)\n",
            "\n",
            "=== Final Model Accuracies ===\n",
            "llama3-70b-8192: 0.686\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "from openai import OpenAI\n",
        "\n",
        "# --- 1. Setup OpenRouter client ---\n",
        "GROQ_API_KEY = \"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\"\n",
        "client = OpenAI(\n",
        "    base_url=\"https://api.groq.com/openai/v1\",\n",
        "    api_key=GROQ_API_KEY\n",
        ")\n",
        "\n",
        "# --- 2. System Prompt ---\n",
        "SYSTEM_PROMPT = (\n",
        "    \"You are a medical examination assistant. \"\n",
        "    \"For every batch you will receive exactly <=10 multiple-choice questions (MCQs) in the format:\\n\\n\"\n",
        "    \"Q1: <question>\\nA. <option>\\nB. <option>\\nC. <option>\\nD. <option>\\n\\n\"\n",
        "    \"Return ONLY one the answer from A,B,C or D (nothing else should be included in answer), for each question STRICTLY IN FORMAT:\\n\"\n",
        "    \"Q1: A, Q2: C, ..., Q20: B\\n\"\n",
        "    \"**IMPORTANT**Do not add explanations or extra text.\"\n",
        ")\n",
        "\n",
        "# --- 3. Ask LLM in Batches of 20 ---\n",
        "def ask_llm_batch_openrouter(questions_batch, model):\n",
        "    prompt = \"\"\n",
        "    for i, row in enumerate(questions_batch, start=1):\n",
        "        prompt += (\n",
        "\n",
        "            f\"Q{i}: {row['question']}\\n\"\n",
        "            f\"A. {row['opa']}\\n\"\n",
        "            f\"B. {row['opb']}\\n\"\n",
        "            f\"C. {row['opc']}\\n\"\n",
        "            f\"D. {row['opd']}\\n\\n\"\n",
        "        )\n",
        "    prompt += \"Write your answers now:\\n\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0,\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "# --- 4. Parse answer letters A/B/C/D into 0/1/2/3 ---\n",
        "def parse_batch_answers(response_text, expected_len):\n",
        "    matches = re.findall(r\"Q\\d+:\\s*([A-D])\", response_text, flags=re.IGNORECASE)\n",
        "    preds = [ord(m.upper()) - 65 for m in matches[:expected_len]]\n",
        "    return preds\n",
        "\n",
        "# --- 5. Load Validation Data ---\n",
        "validation_df = pd.read_csv('/content/drive/MyDrive/MedDataset/validation.csv')\n",
        "validation_df.info()\n",
        "# validation_df=validation_df.head(200)\n",
        "\n",
        "# --- 6. Define Models to Evaluate ---\n",
        "models = [\n",
        "    \"llama3-70b-8192\",\n",
        "]\n",
        "\n",
        "# --- 7. Batch Evaluation for Each Model ---\n",
        "batch_size = 10\n",
        "results = {}\n",
        "\n",
        "for model_name in models:\n",
        "    print(f\"\\n--- Evaluating {model_name} ---\")\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    total_batches = (len(validation_df) + batch_size - 1) // batch_size\n",
        "    for i in tqdm(range(0, len(validation_df), batch_size), desc=f\"{model_name} Progress\", total=total_batches):\n",
        "\n",
        "        batch_df = validation_df.iloc[i:i + batch_size]\n",
        "        golds = batch_df[\"cop\"].astype(int).map({0:'A', 1:'B', 2:'C', 3:'D'}).tolist()\n",
        "        try:\n",
        "\n",
        "            raw_response = ask_llm_batch_openrouter(batch_df.to_dict(\"records\"), model=model_name)\n",
        "            matches = re.findall(r\"Q\\d+:\\s*([A-D])\", raw_response, flags=re.IGNORECASE)\n",
        "\n",
        "            if len(matches) != len(golds):\n",
        "                print(raw_response)\n",
        "                print(f\"Batch {i//batch_size + 1}: Expected {len(golds)} answers, got {len(matches)}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            preds = [m.upper() for m in matches[:len(golds)]]\n",
        "            correct += sum([int(p == g) for p, g in zip(preds, golds)])\n",
        "            total += len(golds)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in batch {i//batch_size + 1} for model {model_name}: {e}\")\n",
        "            continue\n",
        "\n",
        "    if total > 0:\n",
        "        acc = correct / total\n",
        "        results[model_name] = acc\n",
        "        print(f\"Accuracy for {model_name}: {acc:.3f} ({correct}/{total})\")\n",
        "    else:\n",
        "        print(f\"No batches processed for {model_name}\")\n",
        "\n",
        "# --- 8. Summary ---\n",
        "print(\"\\n=== Final Model Accuracies ===\")\n",
        "for model, acc in results.items():\n",
        "    print(f\"{model}: {acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chain of Thought: llama3-70b-8192(Acc=68.7)"
      ],
      "metadata": {
        "id": "l-VBrgIklQ0m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687,
          "referenced_widgets": [
            "4c8b5f3b4bc34543b18f796fe523130e",
            "0269a20e784e4092b59e206f2f68a283",
            "3fdd9f1a22904ad28618aebbd3ef538d",
            "78876ceb4f4b4c7d9b3114b4e5555c6e",
            "c5148262e0054008ad340dac950dc78f",
            "7aa6a632bd0345fbbb734739aefca8cb",
            "48fa334bef6a4acbba0ff2b7cfe1a6ed",
            "1656ce8c85fc402ea28c8abc0f8d99e9",
            "6913fad7b67a40bcafb1850462bc8684",
            "1b4a7b5e0d3b4541b82f948a73b53589",
            "2198a8165681490e93f8ac0aa898c552"
          ]
        },
        "id": "lx7eSAJG8-iC",
        "outputId": "8e74d328-29aa-43fc-d616-6f9eefdef02e"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Evaluating llama3-70b-8192 ---\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c8b5f3b4bc34543b18f796fe523130e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "llama3-70b-8192 Progress:   0%|          | 0/210 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q1: A\n",
            "Q2: A\n",
            "Q3: B\n",
            "Q4: D\n",
            "Q5: B\n",
            "Q6: A\n",
            "Q7: D\n",
            "Q8: B\n",
            "Q9: D\n",
            "Q10: A\n",
            "Q11: A\n",
            "Q12: None of the above (Note: The options provided are all related to fractures, but the question asks about the most common tumor of the lacrimal gland)\n",
            "Q13: A\n",
            "Q14: C\n",
            "Q15: C\n",
            "Q16: B\n",
            "Q17: C\n",
            "Q18: B\n",
            "Q19: A\n",
            "Q20: A\n",
            "Batch 6: Expected 20 answers, got 19. Skipping.\n",
            "Error in batch 185 for model llama3-70b-8192: no healthy upstream\n",
            "Error in batch 186 for model llama3-70b-8192: no healthy upstream\n",
            "Error in batch 187 for model llama3-70b-8192: no healthy upstream\n",
            "Error in batch 188 for model llama3-70b-8192: no healthy upstream\n",
            "Error in batch 189 for model llama3-70b-8192: no healthy upstream\n",
            "Error in batch 190 for model llama3-70b-8192: no healthy upstream\n",
            "Error in batch 191 for model llama3-70b-8192: no healthy upstream\n",
            "Accuracy for llama3-70b-8192: 0.687 (2762/4023)\n",
            "\n",
            "=== Final Model Accuracies ===\n",
            "llama3-70b-8192: 0.687\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "from tqdm.auto import tqdm\n",
        "# --- 1. Setup OpenRouter client ---\n",
        "GROQ_API_KEY = \"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\"\n",
        "client = OpenAI(\n",
        "    base_url=\"https://api.groq.com/openai/v1\",\n",
        "    api_key=GROQ_API_KEY\n",
        ")\n",
        "batch_size = 20\n",
        "# --- 2. System Prompt ---\n",
        "SYSTEM_PROMPT_COT = (\n",
        "    \"You are a medical assistant answering MCQs. For each question, think why each option is right or wrong briefly, then pick the most appropriate answer.\"\n",
        "    \"Return ONLY one answer from A,B,C or D (nothing else should be included in answer), for each {{batch_size}} question STRICTLY IN FORMAT:\\n\"\n",
        "    \"Q1: A, Q2: C, ..., Q10: B\\n\"\n",
        "    \"**IMPORTANT**Do not add explanations or extra text.\"\n",
        ")\n",
        "\n",
        "# --- 3. Ask LLM in Batches of 20 ---\n",
        "def ask_llm_batch_openrouter(questions_batch, model):\n",
        "    prompt = \"\"\n",
        "    for i, row in enumerate(questions_batch, start=1):\n",
        "        prompt += (\n",
        "\n",
        "            f\"Q{i}: {row['question']}\\n\"\n",
        "            f\"A. {row['opa']}\\n\"\n",
        "            f\"B. {row['opb']}\\n\"\n",
        "            f\"C. {row['opc']}\\n\"\n",
        "            f\"D. {row['opd']}\\n\\n\"\n",
        "        )\n",
        "    prompt += \"Write your answers now:\\n\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT_COT},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0,\n",
        "        max_tokens=130,\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "# --- 4. Parse answer letters A/B/C/D into 0/1/2/3 ---\n",
        "def parse_batch_answers(response_text, expected_len):\n",
        "    matches = re.findall(r\"Q\\d+:\\s*([A-D])\", response_text, flags=re.IGNORECASE)\n",
        "    preds = [ord(m.upper()) - 65 for m in matches[:expected_len]]\n",
        "    return preds\n",
        "\n",
        "# --- 5. Load Validation Data ---\n",
        "validation_df = pd.read_csv('/content/drive/MyDrive/MedDataset/validation.csv')\n",
        "# validation_df.info()\n",
        "# validation_df=validation_df.head(200)\n",
        "\n",
        "# --- 6. Define Models to Evaluate ---\n",
        "models = [\n",
        "    \"llama3-70b-8192\",\n",
        "]\n",
        "\n",
        "# --- 7. Batch Evaluation for Each Model ---\n",
        "\n",
        "results = {}\n",
        "\n",
        "for model_name in models:\n",
        "    print(f\"\\n--- Evaluating {model_name} ---\")\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    total_batches = (len(validation_df) + batch_size - 1) // batch_size\n",
        "    for i in tqdm(range(0, len(validation_df), batch_size), desc=f\"{model_name} Progress\", total=total_batches):\n",
        "\n",
        "        batch_df = validation_df.iloc[i:i + batch_size]\n",
        "        golds = batch_df[\"cop\"].astype(int).map({0:'A', 1:'B', 2:'C', 3:'D'}).tolist()\n",
        "\n",
        "        try:\n",
        "\n",
        "            raw_response = ask_llm_batch_openrouter(batch_df.to_dict(\"records\"), model=model_name)\n",
        "            matches = re.findall(r\"Q\\d+:\\s*([A-D])\", raw_response, flags=re.IGNORECASE)\n",
        "\n",
        "\n",
        "            if len(matches) != len(golds):\n",
        "                print(raw_response)\n",
        "                print(f\"Batch {i//batch_size + 1}: Expected {len(golds)} answers, got {len(matches)}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            preds = [m.upper() for m in matches[:len(golds)]]\n",
        "            correct += sum([int(p == g) for p, g in zip(preds, golds)])\n",
        "            total += len(golds)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in batch {i//batch_size + 1} for model {model_name}: {e}\")\n",
        "            continue\n",
        "\n",
        "    if total > 0:\n",
        "        acc = correct / total\n",
        "        results[model_name] = acc\n",
        "        print(f\"Accuracy for {model_name}: {acc:.3f} ({correct}/{total})\")\n",
        "    else:\n",
        "        print(f\"No batches processed for {model_name}\")\n",
        "\n",
        "# --- 8. Summary ---\n",
        "print(\"\\n=== Final Model Accuracies ===\")\n",
        "for model, acc in results.items():\n",
        "    print(f\"{model}: {acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z6XEVuWwuKmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tree of Thought: llama3-70b-8192"
      ],
      "metadata": {
        "id": "QixzcKIFlXQ2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baFsAV3x8-eq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6d606c677e87437091d84008f990dba4",
            "e06a539c9f2c406d848c8461166f033f",
            "c693f813fa29465fa4ee3860d385cbd7",
            "332b3bb8361f41b8922bc79bb895eaee",
            "4276a90de1504948a6b6dd6380f36a1c",
            "5fdb89d13ca64b16b27f663df783a269",
            "c1a61cbdf52441f195fee31a3f5bcba7",
            "6f0bfdb337824551a59dd892a78f3486",
            "bce3da99b7a143cb84e3ed116bcb5bcb",
            "d4c68c3f08494338bbc0d98bc4703194",
            "0d1218718ceb4ea4b8677c7e5a1e2427"
          ]
        },
        "collapsed": true,
        "outputId": "4c86e003-961d-4c7c-9c14-4a12205abbfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating llama3-70b-8192 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "llama3-70b-8192 Progress:   0%|          | 0/419 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d606c677e87437091d84008f990dba4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in batch 1 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500043, Requested 736. Please try again in 2m14.7308s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 2 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500043, Requested 652. Please try again in 2m0.1376s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 3 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500042, Requested 594. Please try again in 1m50.0312s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 4 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500042, Requested 621. Please try again in 1m54.6148s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 5 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500041, Requested 514. Please try again in 1m36.0482s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 6 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500040, Requested 482. Please try again in 1m30.258599999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 7 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500039, Requested 597. Please try again in 1m50.0406s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 8 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500039, Requested 578. Please try again in 1m46.680399999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 9 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500038, Requested 552. Please try again in 1m42.1086s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 10 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500038, Requested 588. Please try again in 1m48.2534s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 11 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500038, Requested 527. Please try again in 1m37.637599999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 12 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500037, Requested 465. Please try again in 1m26.848s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 13 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500037, Requested 514. Please try again in 1m35.2382s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 14 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500036, Requested 545. Please try again in 1m40.512999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 15 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500036, Requested 569. Please try again in 1m44.5812s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 16 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500035, Requested 524. Please try again in 1m36.6912s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 17 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500035, Requested 494. Please try again in 1m31.4282s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 18 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500034, Requested 559. Please try again in 1m42.580199999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 19 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500034, Requested 458. Please try again in 1m25.0504s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 20 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500033, Requested 594. Please try again in 1m48.4752s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 21 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500033, Requested 609. Please try again in 1m50.9912s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 22 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500032, Requested 697. Please try again in 2m6.118599999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 23 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500032, Requested 531. Please try again in 1m37.3578s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 24 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500031, Requested 688. Please try again in 2m4.412399999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 25 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500031, Requested 463. Please try again in 1m25.4544s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 26 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500031, Requested 468. Please try again in 1m26.2384s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 27 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500030, Requested 659. Please try again in 1m59.1672s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 28 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500030, Requested 801. Please try again in 2m23.6268s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 29 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500029, Requested 777. Please try again in 2m19.4056s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 30 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500029, Requested 611. Please try again in 1m50.643799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 31 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500028, Requested 569. Please try again in 1m43.3082s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 32 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500028, Requested 643. Please try again in 1m56.0184s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 33 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500027, Requested 588. Please try again in 1m46.4374s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 34 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500027, Requested 485. Please try again in 1m28.561999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 35 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500027, Requested 449. Please try again in 1m22.2642s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 36 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500026, Requested 710. Please try again in 2m7.268s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 37 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500026, Requested 572. Please try again in 1m43.3396s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 38 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500025, Requested 587. Please try again in 1m45.856599999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 39 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500025, Requested 501. Please try again in 1m30.9168s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 40 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500024, Requested 508. Please try again in 1m32.0484s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 41 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500024, Requested 616. Please try again in 1m50.6338s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 42 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500023, Requested 591. Please try again in 1m46.2338s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 43 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500023, Requested 560. Please try again in 1m40.784s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 44 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500022, Requested 570. Please try again in 1m42.424999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 45 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500022, Requested 657. Please try again in 1m57.3836s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 46 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500021, Requested 582. Please try again in 1m44.345599999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 47 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500021, Requested 582. Please try again in 1m44.271599999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 48 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500020, Requested 566. Please try again in 1m41.4268s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 49 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500020, Requested 606. Please try again in 1m48.2648s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 50 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500020, Requested 569. Please try again in 1m41.793199999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 51 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500019, Requested 554. Please try again in 1m39.124199999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 52 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500019, Requested 551. Please try again in 1m38.5108s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 53 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500018, Requested 599. Please try again in 1m46.7022s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 54 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500018, Requested 587. Please try again in 1m44.544599999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 55 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500017, Requested 535. Please try again in 1m35.482999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 56 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500017, Requested 492. Please try again in 1m27.967599999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 57 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500016, Requested 539. Please try again in 1m36.0132s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 58 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500016, Requested 589. Please try again in 1m44.5752s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 59 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500015, Requested 829. Please try again in 2m25.9712s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 60 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500015, Requested 566. Please try again in 1m40.445799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 61 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500014, Requested 592. Please try again in 1m44.8626s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 62 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500014, Requested 560. Please try again in 1m39.253999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 63 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500013, Requested 540. Please try again in 1m35.716s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 64 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500013, Requested 660. Please try again in 1m56.372999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 65 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500013, Requested 592. Please try again in 1m44.5486s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 66 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500012, Requested 711. Please try again in 2m5.034799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 67 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500012, Requested 583. Please try again in 1m42.839399999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 68 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500011, Requested 496. Please try again in 1m27.715799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 69 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500011, Requested 567. Please try again in 1m39.9076s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 70 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500010, Requested 710. Please try again in 2m4.536s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 71 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500010, Requested 703. Please try again in 2m3.2404s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 72 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500009, Requested 580. Please try again in 1m41.91s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 73 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500009, Requested 562. Please try again in 1m38.7256s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 74 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500008, Requested 622. Please try again in 1m49.0176s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 75 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500008, Requested 709. Please try again in 2m3.9772s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 76 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500008, Requested 764. Please try again in 2m13.4032s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 77 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500007, Requested 631. Please try again in 1m50.343799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 78 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500007, Requested 691. Please try again in 2m0.629799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 79 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500006, Requested 595. Please try again in 1m43.95s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 80 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500006, Requested 493. Please try again in 1m26.2324s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 81 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500005, Requested 620. Please try again in 1m48.079s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 82 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500004, Requested 753. Please try again in 2m10.969399999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 83 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500004, Requested 624. Please try again in 1m48.6042s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 84 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500004, Requested 626. Please try again in 1m48.873799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 85 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500003, Requested 703. Please try again in 2m2.1004s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 86 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500003, Requested 664. Please try again in 1m55.2872s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 87 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500002, Requested 595. Please try again in 1m43.285999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 88 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500002, Requested 680. Please try again in 1m57.898s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 89 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500001, Requested 598. Please try again in 1m43.653399999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 90 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500001, Requested 587. Please try again in 1m41.6776s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 91 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500000, Requested 607. Please try again in 1m45.0596s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 92 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500000, Requested 640. Please try again in 1m50.687999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 93 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500000, Requested 520. Please try again in 1m29.875s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 94 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500000, Requested 496. Please try again in 1m25.6528s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 95 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500000, Requested 531. Please try again in 1m31.6268s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 96 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499999, Requested 487. Please try again in 1m23.9496s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 97 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499999, Requested 528. Please try again in 1m30.959399999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 98 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499998, Requested 605. Please try again in 1m44.190999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 99 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499998, Requested 519. Please try again in 1m29.238199999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 100 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499997, Requested 414. Please try again in 1m11.0092s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 101 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499997, Requested 585. Please try again in 1m40.484s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 102 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499997, Requested 583. Please try again in 1m40.0644s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 103 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499996, Requested 488. Please try again in 1m23.5744s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 104 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499996, Requested 555. Please try again in 1m35.076s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 105 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499995, Requested 651. Please try again in 1m51.5898s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 106 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499995, Requested 494. Please try again in 1m24.3882s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 107 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499994, Requested 584. Please try again in 1m39.866199999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 108 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499994, Requested 546. Please try again in 1m33.2258s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 109 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499994, Requested 548. Please try again in 1m33.4964s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 110 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499993, Requested 570. Please try again in 1m37.223s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 111 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499993, Requested 523. Please try again in 1m29.0264s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 112 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499992, Requested 525. Please try again in 1m29.297s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 113 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499992, Requested 548. Please try again in 1m33.1944s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 114 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499991, Requested 475. Please try again in 1m20.506s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 115 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499991, Requested 568. Please try again in 1m36.5004s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 116 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499991, Requested 662. Please try again in 1m52.6686s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 117 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499990, Requested 507. Please try again in 1m25.7956s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 118 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499990, Requested 588. Please try again in 1m39.7064s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 119 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499989, Requested 643. Please try again in 1m49.137399999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 120 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499989, Requested 478. Please try again in 1m20.5484s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 121 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499988, Requested 644. Please try again in 1m49.1592s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 122 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499988, Requested 647. Please try again in 1m49.5966s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 123 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499987, Requested 518. Please try again in 1m27.230399999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 124 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499987, Requested 540. Please try again in 1m30.952s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 125 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499986, Requested 550. Please try again in 1m32.601999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 126 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499986, Requested 493. Please try again in 1m22.6764s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 127 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499986, Requested 611. Please try again in 1m42.9928s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 128 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499985, Requested 663. Please try again in 1m51.8834s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 129 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499984, Requested 605. Please try again in 1m41.777999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 130 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499984, Requested 535. Please try again in 1m29.604999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 131 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499984, Requested 761. Please try again in 2m8.5728s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 132 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499983, Requested 493. Please try again in 1m22.1804s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 133 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499983, Requested 714. Please try again in 2m0.2932s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 134 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499982, Requested 551. Please try again in 1m32.048799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 135 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499982, Requested 582. Please try again in 1m37.3256s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 136 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499981, Requested 603. Please try again in 1m40.872399999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 137 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499981, Requested 691. Please try again in 1m56.0028s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 138 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499980, Requested 667. Please try again in 1m51.7766s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 139 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499980, Requested 497. Please try again in 1m22.3256s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 140 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499979, Requested 503. Please try again in 1m23.2874s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 141 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499979, Requested 514. Please try again in 1m25.1132s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 142 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499979, Requested 484. Please try again in 1m19.8532s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 143 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499978, Requested 621. Please try again in 1m43.451799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 144 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499978, Requested 611. Please try again in 1m41.6468s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 145 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499977, Requested 523. Please try again in 1m26.3664s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 146 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499977, Requested 519. Please try again in 1m25.598199999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 147 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499976, Requested 554. Please try again in 1m31.571199999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 148 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499976, Requested 534. Please try again in 1m28.0362s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 149 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499976, Requested 591. Please try again in 1m37.811799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 150 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499975, Requested 608. Please try again in 1m40.6704s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 151 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499975, Requested 557. Please try again in 1m31.7806s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 152 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499974, Requested 669. Please try again in 1m51.0562s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 153 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499974, Requested 710. Please try again in 1m58.062999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 154 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499973, Requested 566. Please try again in 1m33.0988s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 155 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499973, Requested 582. Please try again in 1m35.788599999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 156 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499972, Requested 553. Please try again in 1m30.6874s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 157 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499972, Requested 628. Please try again in 1m43.5504s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 158 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499971, Requested 615. Please try again in 1m41.219s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 159 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499971, Requested 593. Please try again in 1m37.3214s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 160 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499970, Requested 483. Please try again in 1m18.2284s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 161 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499970, Requested 463. Please try again in 1m14.6744s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 162 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499969, Requested 531. Please try again in 1m26.344799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 163 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499969, Requested 494. Please try again in 1m19.8762s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 164 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499968, Requested 594. Please try again in 1m37.065199999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 165 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499968, Requested 518. Please try again in 1m23.8454s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 166 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499967, Requested 553. Please try again in 1m29.7914s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 167 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499967, Requested 538. Please try again in 1m27.1244s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 168 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499966, Requested 565. Please try again in 1m31.713s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 169 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499966, Requested 579. Please try again in 1m34.041199999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 170 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499965, Requested 462. Please try again in 1m13.7466s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 171 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499965, Requested 528. Please try again in 1m25.0674s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 172 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499964, Requested 585. Please try again in 1m34.837s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 173 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499964, Requested 535. Please try again in 1m26.104s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 174 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499963, Requested 634. Please try again in 1m43.1282s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 175 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499963, Requested 623. Please try again in 1m41.1514s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 176 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499962, Requested 535. Please try again in 1m25.866999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 177 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499962, Requested 553. Please try again in 1m28.887399999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 178 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499961, Requested 547. Please try again in 1m27.7666s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 179 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499961, Requested 551. Please try again in 1m28.3798s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 180 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499961, Requested 568. Please try again in 1m31.2424s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 181 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499960, Requested 573. Please try again in 1m32.0304s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 182 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499960, Requested 682. Please try again in 1m50.7866s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 183 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499959, Requested 573. Please try again in 1m31.8774s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 184 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499959, Requested 604. Please try again in 1m37.1582s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 185 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499958, Requested 541. Please try again in 1m26.189799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 186 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499958, Requested 625. Please try again in 1m40.63s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 187 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499957, Requested 680. Please try again in 1m50.053s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 188 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499957, Requested 647. Please try again in 1m44.2756s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 189 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499957, Requested 620. Please try again in 1m39.534s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 190 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499956, Requested 533. Please try again in 1m24.4214s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 191 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499956, Requested 589. Please try again in 1m34.0232s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 192 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499955, Requested 499. Please try again in 1m18.3872s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 193 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499955, Requested 530. Please try again in 1m23.667999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 194 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499954, Requested 602. Please try again in 1m36.031599999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 195 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499954, Requested 583. Please try again in 1m32.665399999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 196 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499953, Requested 483. Please try again in 1m15.296399999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 197 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499953, Requested 668. Please try again in 1m47.1884s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 198 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499952, Requested 585. Please try again in 1m32.746s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 199 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499952, Requested 577. Please try again in 1m31.260599999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 200 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499951, Requested 560. Please try again in 1m28.235s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 201 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499951, Requested 552. Please try again in 1m26.7746s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 202 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499950, Requested 486. Please try again in 1m15.2648s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 203 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499950, Requested 614. Please try again in 1m37.3052s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 204 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499949, Requested 611. Please try again in 1m36.704799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 205 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499949, Requested 546. Please try again in 1m25.391799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 206 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499948, Requested 590. Please try again in 1m32.912s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 207 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499948, Requested 543. Please try again in 1m24.7124s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 208 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499947, Requested 483. Please try again in 1m14.2644s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 209 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499947, Requested 683. Please try again in 1m48.733399999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 210 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499946, Requested 584. Please try again in 1m31.5282s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 211 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499946, Requested 617. Please try again in 1m37.143599999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 212 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499945, Requested 618. Please try again in 1m37.2344s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 213 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499945, Requested 499. Please try again in 1m16.5942s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 214 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499944, Requested 593. Please try again in 1m32.756399999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 215 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499944, Requested 532. Please try again in 1m22.1336s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 216 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499943, Requested 605. Please try again in 1m34.672999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 217 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499943, Requested 470. Please try again in 1m11.268s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 218 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499942, Requested 543. Please try again in 1m23.8024s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 219 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499942, Requested 716. Please try again in 1m53.617799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 220 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499942, Requested 559. Please try again in 1m26.4142s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 221 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499941, Requested 701. Please try again in 1m50.8748s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 222 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499941, Requested 553. Please try again in 1m25.224399999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 223 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499940, Requested 551. Please try again in 1m24.7878s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 224 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499940, Requested 571. Please try again in 1m28.1608s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 225 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499939, Requested 440. Please try again in 1m5.450999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 226 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499939, Requested 566. Please try again in 1m27.1488s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 227 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499938, Requested 613. Please try again in 1m35.195399999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 228 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499938, Requested 539. Please try again in 1m22.3342s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 229 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499938, Requested 561. Please try again in 1m26.0608s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 230 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499937, Requested 604. Please try again in 1m33.4172s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 231 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499937, Requested 596. Please try again in 1m31.9588s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 232 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499936, Requested 607. Please try again in 1m33.7676s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 233 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499936, Requested 678. Please try again in 1m45.948399999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 234 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499935, Requested 576. Please try again in 1m28.2278s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 235 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499935, Requested 507. Please try again in 1m16.2206s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 236 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499934, Requested 563. Please try again in 1m25.8194s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 237 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499934, Requested 517. Please try again in 1m17.7936s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 238 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499933, Requested 685. Please try again in 1m46.746s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 239 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499933, Requested 492. Please try again in 1m13.3206s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 240 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499932, Requested 684. Please try again in 1m46.418199999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 241 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499932, Requested 562. Please try again in 1m25.2606s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 242 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499931, Requested 706. Please try again in 1m50.0668s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 243 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499931, Requested 551. Please try again in 1m23.2088s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 244 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499931, Requested 637. Please try again in 1m37.9936s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 245 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499930, Requested 502. Please try again in 1m14.5916s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 246 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499930, Requested 550. Please try again in 1m22.811s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 247 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499929, Requested 761. Please try again in 1m59.1818s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 248 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499929, Requested 751. Please try again in 1m57.367799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 249 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499928, Requested 579. Please try again in 1m27.5702s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 250 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499928, Requested 617. Please try again in 1m34.0366s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 251 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499927, Requested 607. Please try again in 1m32.2236s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 252 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499927, Requested 572. Please try again in 1m26.0976s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 253 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499926, Requested 526. Please try again in 1m18.070799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 254 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499926, Requested 653. Please try again in 1m39.938399999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 255 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499925, Requested 635. Please try again in 1m36.75s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 256 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499925, Requested 499. Please try again in 1m13.1732s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 257 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499925, Requested 522. Please try again in 1m17.0706s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 258 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499924, Requested 544. Please try again in 1m20.7952s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 259 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499924, Requested 561. Please try again in 1m23.6588s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 260 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499923, Requested 614. Please try again in 1m32.7362s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 261 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499923, Requested 628. Please try again in 1m35.0814s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 262 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499922, Requested 614. Please try again in 1m32.5852s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 263 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499922, Requested 656. Please try again in 1m39.7678s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 264 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499921, Requested 672. Please try again in 1m42.4566s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 265 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499921, Requested 565. Please try again in 1m23.878999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 266 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499920, Requested 576. Please try again in 1m25.703799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 267 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499920, Requested 547. Please try again in 1m20.615599999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 268 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499920, Requested 630. Please try again in 1m34.878s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 269 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499919, Requested 580. Please try again in 1m26.163s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 270 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499919, Requested 516. Please try again in 1m15.0248s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 271 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499918, Requested 533. Please try again in 1m17.8874s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 272 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499918, Requested 559. Please try again in 1m22.306199999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 273 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499917, Requested 558. Please try again in 1m22.058399999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 274 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499917, Requested 777. Please try again in 1m59.826599999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 275 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499916, Requested 513. Please try again in 1m14.1274s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 276 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499916, Requested 571. Please try again in 1m24.0748s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 277 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499916, Requested 559. Please try again in 1m21.9262s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 278 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499915, Requested 667. Please try again in 1m40.5126s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 279 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499915, Requested 519. Please try again in 1m14.860199999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 280 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499914, Requested 531. Please try again in 1m16.8578s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 281 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499914, Requested 566. Please try again in 1m22.8288s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 282 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499913, Requested 576. Please try again in 1m24.480799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 283 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499913, Requested 570. Please try again in 1m23.353s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 284 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499912, Requested 525. Please try again in 1m15.494s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 285 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499912, Requested 621. Please try again in 1m32.0098s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 286 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499912, Requested 500. Please try again in 1m11.026s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 287 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499911, Requested 550. Please try again in 1m19.591s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 288 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499911, Requested 720. Please try again in 1m48.887s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 289 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499910, Requested 506. Please try again in 1m11.8308s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 290 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499910, Requested 649. Please try again in 1m36.450199999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 291 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499909, Requested 605. Please try again in 1m28.741s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 292 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499909, Requested 504. Please try again in 1m11.2002s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 293 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499908, Requested 497. Please try again in 1m9.9146s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 294 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499908, Requested 622. Please try again in 1m31.4376s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 295 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499907, Requested 594. Please try again in 1m26.5242s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 296 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499907, Requested 566. Please try again in 1m21.6098s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 297 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499906, Requested 543. Please try again in 1m17.5604s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 298 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499906, Requested 619. Please try again in 1m30.6022s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 299 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499905, Requested 702. Please try again in 1m44.8596s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 300 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499905, Requested 466. Please try again in 1m4.002799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 301 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499904, Requested 585. Please try again in 1m24.49s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 302 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499904, Requested 698. Please try again in 1m43.9314s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 303 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499904, Requested 571. Please try again in 1m21.9098s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 304 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499903, Requested 573. Please try again in 1m22.1634s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 305 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499902, Requested 561. Please try again in 1m20.0038s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 306 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499902, Requested 483. Please try again in 1m6.451399999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 307 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499902, Requested 490. Please try again in 1m7.584999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 308 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499901, Requested 642. Please try again in 1m33.7726s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 309 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499901, Requested 561. Please try again in 1m19.6998s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 310 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499900, Requested 548. Please try again in 1m17.378399999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 311 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499900, Requested 601. Please try again in 1m26.4578s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 312 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499899, Requested 505. Please try again in 1m9.792999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 313 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499899, Requested 581. Please try again in 1m22.8478s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 314 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499898, Requested 515. Please try again in 1m11.363999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 315 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499898, Requested 574. Please try again in 1m21.479199999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 316 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499897, Requested 610. Please try again in 1m27.608s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 317 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499897, Requested 677. Please try again in 1m39.0966s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 318 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499897, Requested 612. Please try again in 1m27.7876s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 319 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499896, Requested 472. Please try again in 1m3.517599999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 320 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499896, Requested 626. Please try again in 1m30.053799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 321 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499895, Requested 613. Please try again in 1m27.7304s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 322 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499895, Requested 601. Please try again in 1m25.5758s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 323 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499894, Requested 522. Please try again in 1m11.848599999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 324 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499894, Requested 626. Please try again in 1m29.742799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 325 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499893, Requested 536. Please try again in 1m14.1128s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 326 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499893, Requested 601. Please try again in 1m25.266799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 327 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499892, Requested 639. Please try again in 1m31.7472s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 328 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499892, Requested 634. Please try again in 1m30.7302s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 329 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499891, Requested 662. Please try again in 1m35.4896s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 330 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499891, Requested 503. Please try again in 1m7.9374s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 331 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499890, Requested 625. Please try again in 1m28.932s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 332 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499890, Requested 586. Please try again in 1m22.094799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 333 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499889, Requested 614. Please try again in 1m26.8502s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 334 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499889, Requested 553. Please try again in 1m16.2294s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 335 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499888, Requested 605. Please try again in 1m25.137999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 336 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499888, Requested 705. Please try again in 1m42.334s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 337 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499887, Requested 612. Please try again in 1m26.1806s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 338 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499887, Requested 614. Please try again in 1m26.4472s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 339 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499886, Requested 689. Please try again in 1m39.3152s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 340 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499886, Requested 599. Please try again in 1m23.6752s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 341 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499885, Requested 548. Please try again in 1m14.7844s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 342 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499885, Requested 728. Please try again in 1m45.8094s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 343 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499884, Requested 663. Please try again in 1m34.4884s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 344 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499884, Requested 563. Please try again in 1m17.1294s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 345 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499883, Requested 555. Please try again in 1m15.666s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 346 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499883, Requested 497. Please try again in 1m5.565599999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 347 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499882, Requested 591. Please try again in 1m21.7298s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 348 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499882, Requested 535. Please try again in 1m11.975s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 349 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499882, Requested 535. Please try again in 1m11.896999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 350 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499881, Requested 771. Please try again in 1m52.5978s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 351 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499881, Requested 524. Please try again in 1m9.8382s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 352 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499880, Requested 535. Please try again in 1m11.657s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 353 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499880, Requested 555. Please try again in 1m15.036999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 354 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499879, Requested 648. Please try again in 1m31.028399999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 355 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499879, Requested 723. Please try again in 1m43.9114s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 356 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499878, Requested 569. Please try again in 1m17.2222s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 357 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499878, Requested 571. Please try again in 1m17.4908s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 358 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499877, Requested 525. Please try again in 1m9.464s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 359 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499877, Requested 562. Please try again in 1m15.7786s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 360 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499877, Requested 501. Please try again in 1m5.1548s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 361 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499876, Requested 537. Please try again in 1m11.2966s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 362 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499876, Requested 666. Please try again in 1m33.4908s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 363 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499875, Requested 660. Please try again in 1m32.369s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 364 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499875, Requested 756. Please try again in 1m48.8758s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 365 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499874, Requested 693. Please try again in 1m37.9084s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 366 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499874, Requested 526. Please try again in 1m8.971799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 367 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499873, Requested 741. Please try again in 1m46.0328s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 368 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499873, Requested 595. Please try again in 1m20.716999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 369 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499872, Requested 623. Please try again in 1m25.4804s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 370 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499872, Requested 512. Please try again in 1m6.2226s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 371 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499871, Requested 512. Please try again in 1m6.146599999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 372 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499871, Requested 697. Please try again in 1m38.0326s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 373 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499870, Requested 703. Please try again in 1m38.9754s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 374 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499870, Requested 706. Please try again in 1m39.4108s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 375 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499869, Requested 624. Please try again in 1m25.165199999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 376 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499869, Requested 598. Please try again in 1m20.5924s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 377 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499868, Requested 691. Please try again in 1m36.5838s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 378 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499868, Requested 486. Please try again in 1m1.075799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 379 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499868, Requested 621. Please try again in 1m24.3278s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 380 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499867, Requested 511. Please try again in 1m5.2428s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 381 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499867, Requested 616. Please try again in 1m23.308799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 383 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500144, Requested 505. Please try again in 1m52.232s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 384 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500144, Requested 565. Please try again in 2m2.523999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 385 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500143, Requested 578. Please try again in 2m4.697399999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 386 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500143, Requested 641. Please try again in 2m15.5098s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 387 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500142, Requested 522. Please try again in 1m54.8686s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 388 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500142, Requested 619. Please try again in 2m11.5542s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 389 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500141, Requested 688. Please try again in 2m23.4024s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 390 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500141, Requested 517. Please try again in 1m53.7756s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 391 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500140, Requested 520. Please try again in 1m54.203s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 392 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500140, Requested 538. Please try again in 1m57.242399999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 393 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500139, Requested 508. Please try again in 1m51.9544s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 394 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500139, Requested 715. Please try again in 2m27.652s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 395 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500139, Requested 625. Please try again in 2m12.025999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 396 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500138, Requested 482. Please try again in 1m47.2396s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 397 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500138, Requested 571. Please try again in 2m2.5418s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 398 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500137, Requested 559. Please try again in 2m0.3952s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 399 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500137, Requested 583. Please try again in 2m4.465399999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 400 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500136, Requested 584. Please try again in 2m4.5642s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 401 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500136, Requested 623. Please try again in 2m11.2294s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 402 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500136, Requested 564. Please try again in 2m0.963199999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 403 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500135, Requested 604. Please try again in 2m7.8012s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 404 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500135, Requested 590. Please try again in 2m5.309s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 405 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500134, Requested 612. Please try again in 2m9.0366s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 406 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500134, Requested 476. Please try again in 1m45.459799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 407 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500133, Requested 692. Please try again in 2m22.7116s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 408 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500133, Requested 556. Please try again in 1m59.1368s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 409 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500132, Requested 630. Please try again in 2m11.846s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 410 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500132, Requested 579. Please try again in 2m2.9592s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 411 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500132, Requested 494. Please try again in 1m48.1942s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 412 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500131, Requested 499. Please try again in 1m48.9832s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 413 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500131, Requested 592. Please try again in 2m4.973599999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 414 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500130, Requested 604. Please try again in 2m6.9742s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 415 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500130, Requested 537. Please try again in 1m55.2966s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 416 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500129, Requested 551. Please try again in 1m57.6348s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 417 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500129, Requested 645. Please try again in 2m13.797s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 418 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500128, Requested 602. Please try again in 2m6.261599999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Error in batch 419 for model llama3-70b-8192: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-70b-8192` in organization `org_01jvp6btraetj9pg8agvw334je` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500128, Requested 254. Please try again in 1m6.0522s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "Accuracy for llama3-70b-8192: 0.700 (7/10)\n",
            "\n",
            "=== Final Model Accuracies ===\n",
            "llama3-70b-8192: 0.700\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "\n",
        "# --- 1. Setup OpenRouter client ---\n",
        "GROQ_API_KEY = \"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\"\n",
        "client = OpenAI(\n",
        "    base_url=\"https://api.groq.com/openai/v1\",\n",
        "    api_key=GROQ_API_KEY\n",
        ")\n",
        "\n",
        "# --- 2. System Prompt ---\n",
        "SYSTEM_PROMPT_TOT = (\n",
        "    \"You are a medical assistant evaluating each MCQ with 3 reasoning paths (Path A, B, C). \"\n",
        "    \"After evaluating all options under each path, choose the most consistent answer.\"\n",
        "    \"Return ONLY one the answer from A,B,C or D (nothing else should be included in answer), for each question STRICTLY IN FORMAT:\\n\"\n",
        "    \"Q1: A, Q2: C, ..., Q10: B\\n\"\n",
        "    \"**IMPORTANT**Do not add explanations or extra text.\"\n",
        ")\n",
        "\n",
        "\n",
        "# --- 3. Ask LLM in Batches of 20 ---\n",
        "def ask_llm_batch_openrouter(questions_batch, model):\n",
        "    prompt = \"\"\n",
        "    for i, row in enumerate(questions_batch, start=1):\n",
        "        prompt += (\n",
        "\n",
        "            f\"Q{i}: {row['question']}\\n\"\n",
        "            f\"A. {row['opa']}\\n\"\n",
        "            f\"B. {row['opb']}\\n\"\n",
        "            f\"C. {row['opc']}\\n\"\n",
        "            f\"D. {row['opd']}\\n\\n\"\n",
        "        )\n",
        "    prompt += \"Write your answers now:\\n\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT_TOT},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0,\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "# --- 4. Parse answer letters A/B/C/D into 0/1/2/3 ---\n",
        "def parse_batch_answers(response_text, expected_len):\n",
        "    matches = re.findall(r\"Q\\d+:\\s*([A-D])\", response_text, flags=re.IGNORECASE)\n",
        "    preds = [ord(m.upper()) - 65 for m in matches[:expected_len]]\n",
        "    return preds\n",
        "\n",
        "# --- 5. Load Validation Data ---\n",
        "validation_df = pd.read_csv('/content/drive/MyDrive/MedDataset/validation.csv')\n",
        "# validation_df.info()\n",
        "# validation_df=validation_df.head(200)\n",
        "\n",
        "# --- 6. Define Models to Evaluate ---\n",
        "models = [\n",
        "    \"llama3-70b-8192\",\n",
        "]\n",
        "\n",
        "# --- 7. Batch Evaluation for Each Model ---\n",
        "batch_size = 10\n",
        "results = {}\n",
        "\n",
        "for model_name in models:\n",
        "    print(f\"\\n--- Evaluating {model_name} ---\")\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    total_batches = (len(validation_df) + batch_size - 1) // batch_size\n",
        "    for i in tqdm(range(0, len(validation_df), batch_size), desc=f\"{model_name} Progress\", total=total_batches):\n",
        "\n",
        "        batch_df = validation_df.iloc[i:i + batch_size]\n",
        "        golds = batch_df[\"cop\"].astype(int).map({0:'A', 1:'B', 2:'C', 3:'D'}).tolist()\n",
        "\n",
        "        try:\n",
        "\n",
        "            raw_response = ask_llm_batch_openrouter(batch_df.to_dict(\"records\"), model=model_name)\n",
        "            matches = re.findall(r\"Q\\d+:\\s*([A-D])\", raw_response, flags=re.IGNORECASE)\n",
        "\n",
        "            if len(matches) != len(golds):\n",
        "                print(raw_response)\n",
        "                print(f\"Batch {i//batch_size + 1}: Expected {len(golds)} answers, got {len(matches)}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            preds = [m.upper() for m in matches[:len(golds)]]\n",
        "            correct += sum([int(p == g) for p, g in zip(preds, golds)])\n",
        "            total += len(golds)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in batch {i//batch_size + 1} for model {model_name}: {e}\")\n",
        "            continue\n",
        "\n",
        "    if total > 0:\n",
        "        acc = correct / total\n",
        "        results[model_name] = acc\n",
        "        print(f\"Accuracy for {model_name}: {acc:.3f} ({correct}/{total})\")\n",
        "    else:\n",
        "        print(f\"No batches processed for {model_name}\")\n",
        "\n",
        "# --- 8. Summary ---\n",
        "print(\"\\n=== Final Model Accuracies ===\")\n",
        "for model, acc in results.items():\n",
        "    print(f\"{model}: {acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2E837rA9Ckl"
      },
      "source": [
        "# **OpenRouter**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zero Shot: microsoft/mai-ds-r1:free(Acc=76.3)"
      ],
      "metadata": {
        "id": "_7dKLeDMjDQV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "3b2cf7cfbf3a4cc7a48632dddffcd2b0",
            "fcd296ece1d2457c8e9e6a0bdd3b0b24",
            "a2baa90036784b588ed417e65f678cf7",
            "22f14206f021420a8f6b6f5d47c10f85",
            "0170831185e747c6ae2b9f2e64b855ec",
            "2bc66adbaf3e4d8ea9c165da09fb61cc",
            "81899eedbd2642e38b0b54eb3fb41675",
            "c07e3dcfd8db44049f3d79370a5b0615",
            "48d6c276b9e44f8a8c0097a8f3023362",
            "d6ee56e45d454f129bffdac990634f01",
            "f1ef8809cdc440dbbd40858412516a09"
          ]
        },
        "outputId": "e2dfe62d-3ebd-40ac-de7e-f18627137c1b",
        "id": "DdvD4gCgoXJ3"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Evaluating microsoft/mai-ds-r1:free ---\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b2cf7cfbf3a4cc7a48632dddffcd2b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "microsoft/mai-ds-r1:free Progress:   0%|          | 0/105 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for microsoft/mai-ds-r1:free: 0.763 (3193/4183)\n",
            "\n",
            "=== Final Model Accuracies ===\n",
            "microsoft/mai-ds-r1:free: 0.763\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# --- 1. Setup OpenRouter client ---\n",
        "OPEN_ROUTER_KEY = \"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\"\n",
        "client = OpenAI(\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=OPEN_ROUTER_KEY,\n",
        ")\n",
        "\n",
        "# --- 2. System Prompt ---\n",
        "\n",
        "SYSTEM_PROMPT = (\n",
        "    \"You are a medical examination assistant. \"\n",
        "    \"For every batch you will receive exactly <=10 multiple-choice questions (MCQs) in the format:\\n\\n\"\n",
        "    \"Q1: <question>\\nA. <option>\\nB. <option>\\nC. <option>\\nD. <option>\\n\\n\"\n",
        "    \"Return ONLY one the answer from A,B,C or D (nothing else should be included in answer), for each question STRICTLY IN FORMAT:\\n\"\n",
        "    \"Q1: A, Q2: C, ..., Q20: B\\n\"\n",
        "    \"**IMPORTANT**Do not add explanations or extra text.\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# --- 3. Ask LLM in Batches of 20 ---\n",
        "def ask_llm_batch_openrouter(questions_batch, model):\n",
        "    prompt = \"\"\n",
        "    for i, row in enumerate(questions_batch, start=1):\n",
        "        prompt += (\n",
        "\n",
        "            f\"Q{i}: {row['question']}\\n\"\n",
        "            f\"A. {row['opa']}\\n\"\n",
        "            f\"B. {row['opb']}\\n\"\n",
        "            f\"C. {row['opc']}\\n\"\n",
        "            f\"D. {row['opd']}\\n\\n\"\n",
        "        )\n",
        "    prompt += \"Write your answers now:\\n\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.2,\n",
        "        top_p=0.95,\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "# --- 4. Parse answer letters A/B/C/D into 0/1/2/3 ---\n",
        "def parse_batch_answers(response_text, expected_len):\n",
        "    matches = re.findall(r\"Q\\d+:\\s*([A-D])\", response_text, flags=re.IGNORECASE)\n",
        "    preds = [ord(m.upper()) - 65 for m in matches[:expected_len]]\n",
        "    return preds\n",
        "\n",
        "# --- 5. Load Validation Data ---\n",
        "validation_df = pd.read_csv('/content/drive/MyDrive/MedDataset/validation.csv')\n",
        "# validation_df.info()\n",
        "# validation_df=validation_df.head(100)\n",
        "\n",
        "# --- 6. Define Models to Evaluate ---\n",
        "models = [\n",
        "    \"microsoft/mai-ds-r1:free\",\n",
        "]\n",
        "\n",
        "# --- 7. Batch Evaluation for Each Model ---\n",
        "batch_size = 40\n",
        "results = {}\n",
        "\n",
        "for model_name in models:\n",
        "    print(f\"\\n--- Evaluating {model_name} ---\")\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    total_batches = (len(validation_df) + batch_size - 1) // batch_size\n",
        "    for i in tqdm(range(0, len(validation_df), batch_size), desc=f\"{model_name} Progress\", total=total_batches):\n",
        "\n",
        "        batch_df = validation_df.iloc[i:i + batch_size]\n",
        "        golds = batch_df[\"cop\"].astype(int).map({0:'A', 1:'B', 2:'C', 3:'D'}).tolist()\n",
        "\n",
        "        try:\n",
        "\n",
        "            raw_response = ask_llm_batch_openrouter(batch_df.to_dict(\"records\"), model=model_name)\n",
        "            matches = re.findall(r\"Q\\d+:\\s*([A-D])\", raw_response, flags=re.IGNORECASE)\n",
        "\n",
        "            if len(matches) != len(golds):\n",
        "                print(raw_response)\n",
        "                print(f\"Batch {i//batch_size + 1}: Expected {len(golds)} answers, got {len(matches)}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            preds = [m.upper() for m in matches[:len(golds)]]\n",
        "            correct += sum([int(p == g) for p, g in zip(preds, golds)])\n",
        "            total += len(golds)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in batch {i//batch_size + 1} for model {model_name}: {e}\")\n",
        "            continue\n",
        "\n",
        "    if total > 0:\n",
        "        acc = correct / total\n",
        "        results[model_name] = acc\n",
        "        print(f\"Accuracy for {model_name}: {acc:.3f} ({correct}/{total})\")\n",
        "    else:\n",
        "        print(f\"No batches processed for {model_name}\")\n",
        "\n",
        "# --- 8. Summary ---\n",
        "print(\"\\n=== Final Model Accuracies ===\")\n",
        "for model, acc in results.items():\n",
        "    print(f\"{model}: {acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OI03IdUwn4BM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0G6aU2ZIn3-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6HWjPQOvn36p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zero Shot: Gemini 1.5 flash(Acc=54.9), openai/o4-mini(Acc=80.1)\n"
      ],
      "metadata": {
        "id": "aJd_oTHOhqeT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 321,
          "referenced_widgets": [
            "09392626331242478f271a4cadd46a2b",
            "3bca680dff9346c8bced0aa352c372fe",
            "f6f5eaf89a6e497b8207f368c2bd07f1",
            "5e280d5a9dbb46c382e0ade4c35dbc5d",
            "713caf38591440bd86dd21aa3e60639e",
            "aba6d33820d347879b34dfce16d79b4e",
            "33fe7e53c5a64e869169b46453258057",
            "42fd524bd71b42b6b42cc6c031a93be3",
            "0f6370e66dd1445c97515f0430970e35",
            "7090f4f755b7445fa31c806ebcefc3bd",
            "6095f69db8354709aec7496d8ddfc7f6",
            "d631ba6949864169aea3edc4e8304283",
            "0b59100373c44ea192142c3cc577cbef",
            "cb59c656ec2f47c38893cb47b2887fcc",
            "ccafd8dc61ce402a90f7ed5ec6c54033",
            "75d700f2301f4865affb30f63c270320",
            "0df79dd600aa4d71b7f81e3ee3026d48",
            "234a2c19af8e4120a6db3b15882766e6",
            "2ad7aa0c892e42588e95ee34d6c01331",
            "78e295b1b02f4f3eb7341c40232dc3d1",
            "d3ed1598c3e045918a808af55fb7c405",
            "6749f9de05a54cdda6e941014745f4f7",
            "4b064d3e93dd4c9ab65f96b9927e85b6",
            "f41b125e63b54b6b996d92bc26aac46a",
            "df84ff83048c4dff9a9c26fada16fd12",
            "568c920579dd480bb35eb86d47f5bc92",
            "24029157c43340df8d6f2e97b59a73ec",
            "eeab23cff2c64290b88514ae19eb7741",
            "6f8bb04b19964da4a01b7f61373fb612",
            "3e24261e69f84bbeabe2d9a13f6c066f",
            "11accb582aac4ac79e0b0f6ecaa1bd08",
            "5a1516a834fc4becb9fa78ab3903fc5b",
            "998c8246c3fd405f8543d4db25ec5995"
          ]
        },
        "id": "oidHsWhivZPe",
        "outputId": "9fda868b-70ac-4cf8-a300-f009708e39e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Evaluating google/gemini-flash-1.5-8b ---\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09392626331242478f271a4cadd46a2b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "google/gemini-flash-1.5-8b Progress:   0%|          | 0/419 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for google/gemini-flash-1.5-8b: 0.549 (2295/4183)\n",
            "\n",
            "--- Evaluating openai/o4-mini ---\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d631ba6949864169aea3edc4e8304283",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "openai/o4-mini Progress:   0%|          | 0/419 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Batch 183: Expected 10 answers, got 0. Skipping.\n",
            "\n",
            "Batch 392: Expected 10 answers, got 0. Skipping.\n",
            "Accuracy for openai/o4-mini: 0.801 (3336/4163)\n",
            "\n",
            "--- Evaluating deepseek/deepseek-r1-0528:free ---\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b064d3e93dd4c9ab65f96b9927e85b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "deepseek/deepseek-r1-0528:free Progress:   0%|          | 0/419 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "\n",
        "# --- 1. Setup OpenRouter client ---\n",
        "OPEN_ROUTER_KEY = \"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\"\n",
        "client = OpenAI(\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=OPEN_ROUTER_KEY,\n",
        ")\n",
        "\n",
        "# --- 2. System Prompt ---\n",
        "SYSTEM_PROMPT = (\n",
        "    \"You are a medical examination assistant. \"\n",
        "    \"For every batch you will receive exactly 20 multiple-choice questions (MCQs) in the format:\\n\\n\"\n",
        "    \"Q1: <question>\\nA. <option>\\nB. <option>\\nC. <option>\\nD. <option>\\n\\n\"\n",
        "    \"Return ONLY one the answer from A,B,C or D (nothing else should be included in answer), for each question STRICTLY IN FORMAT:\\n\"\n",
        "    \"Q1: A, Q2: C, ..., Q10: B\\n\"\n",
        "    \"**IMPORTANT**Do not add explanations or extra text.\"\n",
        ")\n",
        "\n",
        "# --- 3. Ask LLM in Batches of 20 ---\n",
        "def ask_llm_batch_openrouter(questions_batch, model):\n",
        "    prompt = \"\"\n",
        "    for i, row in enumerate(questions_batch, start=1):\n",
        "        prompt += (\n",
        "\n",
        "            f\"Q{i}: {row['question']}\\n\"\n",
        "            f\"A. {row['opa']}\\n\"\n",
        "            f\"B. {row['opb']}\\n\"\n",
        "            f\"C. {row['opc']}\\n\"\n",
        "            f\"D. {row['opd']}\\n\\n\"\n",
        "        )\n",
        "    prompt += \"Write your answers now:\\n\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.2,\n",
        "        top_p=0.95,\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "# --- 4. Parse answer letters A/B/C/D into 0/1/2/3 ---\n",
        "def parse_batch_answers(response_text, expected_len):\n",
        "    matches = re.findall(r\"Q\\d+:\\s*([A-D])\", response_text, flags=re.IGNORECASE)\n",
        "    preds = [ord(m.upper()) - 65 for m in matches[:expected_len]]\n",
        "    return preds\n",
        "\n",
        "# --- 5. Load Validation Data ---\n",
        "validation_df = pd.read_csv('/content/drive/MyDrive/MedDataset/validation.csv')\n",
        "# validation_df.info()\n",
        "# validation_df=validation_df.head(200)\n",
        "\n",
        "# --- 6. Define Models to Evaluate ---\n",
        "models = [\n",
        "    \"google/gemini-flash-1.5-8b\",\n",
        "    \"openai/o4-mini\",\n",
        "\n",
        "]\n",
        "\n",
        "# --- 7. Batch Evaluation for Each Model ---\n",
        "batch_size = 10\n",
        "results = {}\n",
        "\n",
        "for model_name in models:\n",
        "    print(f\"\\n--- Evaluating {model_name} ---\")\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    total_batches = (len(validation_df) + batch_size - 1) // batch_size\n",
        "    for i in tqdm(range(0, len(validation_df), batch_size), desc=f\"{model_name} Progress\", total=total_batches):\n",
        "\n",
        "        batch_df = validation_df.iloc[i:i + batch_size]\n",
        "        golds = batch_df[\"cop\"].astype(int).map({0:'A', 1:'B', 2:'C', 3:'D'}).tolist()\n",
        "\n",
        "        try:\n",
        "\n",
        "            raw_response = ask_llm_batch_openrouter(batch_df.to_dict(\"records\"), model=model_name)\n",
        "            matches = re.findall(r\"Q\\d+:\\s*([A-D])\", raw_response, flags=re.IGNORECASE)\n",
        "\n",
        "            if len(matches) != len(golds):\n",
        "                print(raw_response)\n",
        "                print(f\"Batch {i//batch_size + 1}: Expected {len(golds)} answers, got {len(matches)}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            preds = [m.upper() for m in matches[:len(golds)]]\n",
        "            correct += sum([int(p == g) for p, g in zip(preds, golds)])\n",
        "            total += len(golds)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in batch {i//batch_size + 1} for model {model_name}: {e}\")\n",
        "            continue\n",
        "\n",
        "    if total > 0:\n",
        "        acc = correct / total\n",
        "        results[model_name] = acc\n",
        "        print(f\"Accuracy for {model_name}: {acc:.3f} ({correct}/{total})\")\n",
        "    else:\n",
        "        print(f\"No batches processed for {model_name}\")\n",
        "\n",
        "# --- 8. Summary ---\n",
        "print(\"\\n=== Final Model Accuracies ===\")\n",
        "for model, acc in results.items():\n",
        "    print(f\"{model}: {acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chain of Thought: Gemini 1.5 flash(Acc=55.6)"
      ],
      "metadata": {
        "id": "lokkImNCl91o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58zpzhxV6_W4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507,
          "referenced_widgets": [
            "f84b412da83e42968e4aedc8f064132a",
            "5127c4e8f3774a7fb8f0f8ca32188f27",
            "cd227b74d4774b4e9f8be80e0463ac79",
            "3a02231d286646538781d3873432a819",
            "d48e0548568a45698163fe1f20d8ce87",
            "0a77a456168a482f8e5ca160201ade7f",
            "e93fa03d482243558d79e553242501d9",
            "48fbd03095574fbf8cd2e9abaf0544fa",
            "23477b5c33814675b196774a41b4353b",
            "706ae0c483be4967aa04a9d89c8837b7",
            "f44e01386237462489d0561da307a6da",
            "6e6dfe8e8c894b80a7402380f0f455c6",
            "222da82207514ef2b6f5bee48a40ed9d",
            "b81d9d48942c41349d5f60ae65318be4",
            "1ca1acf6992b4fe9b04eb35e377d3242",
            "98522606ffb54763baf5d6c3ac09cad4",
            "1fe53fd9e658497db06e8fbeea4af497",
            "133936f81bb3433295d9e72022031f8b",
            "11dd800626664bc48f374dbbbce24d08",
            "796fdef1c4e949e9b220e1cf9fe12319",
            "8296749880e14621a66b4da74cd729a7",
            "fdf68c28138c453383fa340be0516376"
          ]
        },
        "outputId": "4e941f34-0e46-4e78-9db5-a2bb73f5b834"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating google/gemini-flash-1.5-8b ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "google/gemini-flash-1.5-8b Progress:   0%|          | 0/419 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f84b412da83e42968e4aedc8f064132a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for google/gemini-flash-1.5-8b: 0.556 (2325/4183)\n",
            "\n",
            "--- Evaluating deepseek/deepseek-r1-0528:free ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "deepseek/deepseek-r1-0528:free Progress:   0%|          | 0/419 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e6dfe8e8c894b80a7402380f0f455c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-1713622778.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mraw_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mask_llm_batch_openrouter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"records\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"Q\\d+:\\s*([A-D])\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIGNORECASE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2-1713622778.py\u001b[0m in \u001b[0;36mask_llm_batch_openrouter\u001b[0;34m(questions_batch, model)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Write your answers now:\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         messages=[\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    923\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    924\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    926\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1247\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m         )\n\u001b[0;32m-> 1249\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m    970\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m                 response = self._client.send(\n\u001b[0m\u001b[1;32m    973\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                     \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stream_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m     def _send_handling_auth(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \"\"\"\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_content\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36miter_bytes\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mchunker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mByteChunker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mraw_bytes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m                     \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36miter_raw\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mraw_stream_bytes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_bytes_downloaded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_stream_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_stream_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_httpcore_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mShieldCancellation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"receive_response_body\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_body\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 data = self._network_stream.read(\n\u001b[0m\u001b[1;32m    218\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1293\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1295\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1166\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# --- 1. Setup OpenRouter client ---\n",
        "OPEN_ROUTER_KEY = \"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\"\n",
        "client = OpenAI(\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=OPEN_ROUTER_KEY,\n",
        ")\n",
        "\n",
        "# --- 2. System Prompt ---\n",
        "\n",
        "SYSTEM_PROMPT_COT = (\n",
        "    \"You are a medical assistant answering MCQs. For each question, explain why each option is right or wrong briefly, then pick the most appropriate answer.\"\n",
        "    \"Return ONLY one the answer from A,B,C or D (nothing else should be included in answer), for each question STRICTLY IN FORMAT:\\n\"\n",
        "    \"Q1: A, Q2: C, ..., Q10: B\\n\"\n",
        "    \"**IMPORTANT**Do not add explanations or extra text.\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# --- 3. Ask LLM in Batches of 20 ---\n",
        "def ask_llm_batch_openrouter(questions_batch, model):\n",
        "    prompt = \"\"\n",
        "    for i, row in enumerate(questions_batch, start=1):\n",
        "        prompt += (\n",
        "\n",
        "            f\"Q{i}: {row['question']}\\n\"\n",
        "            f\"A. {row['opa']}\\n\"\n",
        "            f\"B. {row['opb']}\\n\"\n",
        "            f\"C. {row['opc']}\\n\"\n",
        "            f\"D. {row['opd']}\\n\\n\"\n",
        "        )\n",
        "    prompt += \"Write your answers now:\\n\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT_COT},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.2,\n",
        "        top_p=0.95,\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "# --- 4. Parse answer letters A/B/C/D into 0/1/2/3 ---\n",
        "def parse_batch_answers(response_text, expected_len):\n",
        "    matches = re.findall(r\"Q\\d+:\\s*([A-D])\", response_text, flags=re.IGNORECASE)\n",
        "    preds = [ord(m.upper()) - 65 for m in matches[:expected_len]]\n",
        "    return preds\n",
        "\n",
        "# --- 5. Load Validation Data ---\n",
        "validation_df = pd.read_csv('/content/drive/MyDrive/MedDataset/validation.csv')\n",
        "# validation_df.info()\n",
        "# validation_df=validation_df.head(100)\n",
        "\n",
        "# --- 6. Define Models to Evaluate ---\n",
        "models = [\n",
        "    \"google/gemini-flash-1.5-8b\",\n",
        "]\n",
        "\n",
        "# --- 7. Batch Evaluation for Each Model ---\n",
        "batch_size = 10\n",
        "results = {}\n",
        "\n",
        "for model_name in models:\n",
        "    print(f\"\\n--- Evaluating {model_name} ---\")\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    total_batches = (len(validation_df) + batch_size - 1) // batch_size\n",
        "    for i in tqdm(range(0, len(validation_df), batch_size), desc=f\"{model_name} Progress\", total=total_batches):\n",
        "\n",
        "        batch_df = validation_df.iloc[i:i + batch_size]\n",
        "        golds = batch_df[\"cop\"].astype(int).map({0:'A', 1:'B', 2:'C', 3:'D'}).tolist()\n",
        "\n",
        "        try:\n",
        "\n",
        "            raw_response = ask_llm_batch_openrouter(batch_df.to_dict(\"records\"), model=model_name)\n",
        "            matches = re.findall(r\"Q\\d+:\\s*([A-D])\", raw_response, flags=re.IGNORECASE)\n",
        "\n",
        "            if len(matches) != len(golds):\n",
        "                print(raw_response)\n",
        "                print(f\"Batch {i//batch_size + 1}: Expected {len(golds)} answers, got {len(matches)}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            preds = [m.upper() for m in matches[:len(golds)]]\n",
        "            correct += sum([int(p == g) for p, g in zip(preds, golds)])\n",
        "            total += len(golds)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in batch {i//batch_size + 1} for model {model_name}: {e}\")\n",
        "            continue\n",
        "\n",
        "    if total > 0:\n",
        "        acc = correct / total\n",
        "        results[model_name] = acc\n",
        "        print(f\"Accuracy for {model_name}: {acc:.3f} ({correct}/{total})\")\n",
        "    else:\n",
        "        print(f\"No batches processed for {model_name}\")\n",
        "\n",
        "# --- 8. Summary ---\n",
        "print(\"\\n=== Final Model Accuracies ===\")\n",
        "for model, acc in results.items():\n",
        "    print(f\"{model}: {acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tree of Thought: Gemini 1.5 flash(Acc=55.0)"
      ],
      "metadata": {
        "id": "hSh92OtQmIbm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lonUumIz4UaP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507,
          "referenced_widgets": [
            "9480b6ee734541dabdb030bf5f6e5237",
            "5c8f40c33d374fc685fb7ef0687ab061",
            "b00d54d7154a4f3ea648c2d6168f013a",
            "3d2fcd6ca5cc47bc902d7f56b8d321ef",
            "60dc8edfee3c485aac82a380f7950116",
            "b570f4a4087e4d41b8162381e3517490",
            "e50ec642adf44e45b24795a94391a407",
            "14432a43aa6a4629b0bc584098e60dc5",
            "2c35a7c61d0f414ba18a4dc00eef0ccf",
            "f68057cf6e3f4f26a07b03b87d8b4d1c",
            "e28e52799d0e4585a3c42afa38dc366f",
            "b941bed380d44d079693960f6e72e0c7",
            "56421ae887214fcba00724d28373e2e4",
            "d1793114c2db41eebd99ca6873b21798",
            "3a1da3b7f1d943b599af0d85e2f66519",
            "5e1905586e474e8e8e3c2c24e3de6c79",
            "b77c814f0e02422d8e0c6560d825472e",
            "226db9024e324e439753ac53adc988d1",
            "278f7d7a4a5f47a5984dfa222b2d68c9",
            "08466ff15d3d47c087147490285e7648",
            "98677c1bcdb347eba2076a8a96162628",
            "73188986e94d46d1b08d0b3ad024598b"
          ]
        },
        "outputId": "000bd29c-db62-43c9-bf1b-01e347841464"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating google/gemini-flash-1.5-8b ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "google/gemini-flash-1.5-8b Progress:   0%|          | 0/419 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9480b6ee734541dabdb030bf5f6e5237"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for google/gemini-flash-1.5-8b: 0.550 (2301/4183)\n",
            "\n",
            "--- Evaluating openai/o4-mini ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "openai/o4-mini Progress:   0%|          | 0/419 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b941bed380d44d079693960f6e72e0c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3-2144303209.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mraw_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mask_llm_batch_openrouter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"records\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"Q\\d+:\\s*([A-D])\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIGNORECASE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3-2144303209.py\u001b[0m in \u001b[0;36mask_llm_batch_openrouter\u001b[0;34m(questions_batch, model)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Write your answers now:\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         messages=[\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    923\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    924\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    926\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1247\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m         )\n\u001b[0;32m-> 1249\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m    970\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m                 response = self._client.send(\n\u001b[0m\u001b[1;32m    973\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                     \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stream_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m     def _send_handling_auth(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \"\"\"\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_content\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36miter_bytes\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mchunker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mByteChunker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mraw_bytes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m                     \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36miter_raw\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mraw_stream_bytes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_bytes_downloaded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_stream_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_stream_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_httpcore_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mShieldCancellation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"receive_response_body\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_body\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 data = self._network_stream.read(\n\u001b[0m\u001b[1;32m    218\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1293\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1295\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1166\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "\n",
        "# --- 1. Setup OpenRouter client ---\n",
        "OPEN_ROUTER_KEY = \"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\"\n",
        "client = OpenAI(\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=OPEN_ROUTER_KEY,\n",
        ")\n",
        "\n",
        "# --- 2. System Prompt ---\n",
        "SYSTEM_PROMPT_TOT = (\n",
        "    \"You are a medical assistant evaluating each MCQ with 3 reasoning paths (Path A, B, C). \"\n",
        "    \"After evaluating all options under each path, choose the most consistent answer.\"\n",
        "    \"Return ONLY one the answer from A,B,C or D (nothing else should be included in answer), for each question STRICTLY IN FORMAT:\\n\"\n",
        "    \"Q1: A, Q2: C, ..., Q10: B\\n\"\n",
        "    \"**IMPORTANT**Do not add explanations or extra text.\"\n",
        ")\n",
        "\n",
        "\n",
        "# --- 3. Ask LLM in Batches of 20 ---\n",
        "def ask_llm_batch_openrouter(questions_batch, model):\n",
        "    prompt = \"\"\n",
        "    for i, row in enumerate(questions_batch, start=1):\n",
        "        prompt += (\n",
        "\n",
        "            f\"Q{i}: {row['question']}\\n\"\n",
        "            f\"A. {row['opa']}\\n\"\n",
        "            f\"B. {row['opb']}\\n\"\n",
        "            f\"C. {row['opc']}\\n\"\n",
        "            f\"D. {row['opd']}\\n\\n\"\n",
        "        )\n",
        "    prompt += \"Write your answers now:\\n\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT_TOT},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.2,\n",
        "        top_p=0.95,\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "# --- 4. Parse answer letters A/B/C/D into 0/1/2/3 ---\n",
        "def parse_batch_answers(response_text, expected_len):\n",
        "    matches = re.findall(r\"Q\\d+:\\s*([A-D])\", response_text, flags=re.IGNORECASE)\n",
        "    preds = [ord(m.upper()) - 65 for m in matches[:expected_len]]\n",
        "    return preds\n",
        "\n",
        "# --- 5. Load Validation Data ---\n",
        "validation_df = pd.read_csv('/content/drive/MyDrive/MedDataset/validation.csv')\n",
        "# validation_df.info()\n",
        "# validation_df=validation_df.head(100)\n",
        "\n",
        "# --- 6. Define Models to Evaluate ---\n",
        "models = [\n",
        "    \"google/gemini-flash-1.5-8b\",\n",
        "\n",
        "]\n",
        "\n",
        "# --- 7. Batch Evaluation for Each Model ---\n",
        "batch_size = 10\n",
        "results = {}\n",
        "\n",
        "for model_name in models:\n",
        "    print(f\"\\n--- Evaluating {model_name} ---\")\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    total_batches = (len(validation_df) + batch_size - 1) // batch_size\n",
        "    for i in tqdm(range(0, len(validation_df), batch_size), desc=f\"{model_name} Progress\", total=total_batches):\n",
        "\n",
        "        batch_df = validation_df.iloc[i:i + batch_size]\n",
        "        golds = batch_df[\"cop\"].astype(int).map({0:'A', 1:'B', 2:'C', 3:'D'}).tolist()\n",
        "\n",
        "        try:\n",
        "\n",
        "            raw_response = ask_llm_batch_openrouter(batch_df.to_dict(\"records\"), model=model_name)\n",
        "            matches = re.findall(r\"Q\\d+:\\s*([A-D])\", raw_response, flags=re.IGNORECASE)\n",
        "\n",
        "            if len(matches) != len(golds):\n",
        "                print(raw_response)\n",
        "                print(f\"Batch {i//batch_size + 1}: Expected {len(golds)} answers, got {len(matches)}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            preds = [m.upper() for m in matches[:len(golds)]]\n",
        "            correct += sum([int(p == g) for p, g in zip(preds, golds)])\n",
        "            total += len(golds)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in batch {i//batch_size + 1} for model {model_name}: {e}\")\n",
        "            continue\n",
        "\n",
        "    if total > 0:\n",
        "        acc = correct / total\n",
        "        results[model_name] = acc\n",
        "        print(f\"Accuracy for {model_name}: {acc:.3f} ({correct}/{total})\")\n",
        "    else:\n",
        "        print(f\"No batches processed for {model_name}\")\n",
        "\n",
        "# --- 8. Summary ---\n",
        "print(\"\\n=== Final Model Accuracies ===\")\n",
        "for model, acc in results.items():\n",
        "    print(f\"{model}: {acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jC0tG8MN8yQZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8vbhpSVvZEd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJghdhjOvZC5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PRFXs1cvY-_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjjCX2c9vY73"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPxxJx75vY4-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7u8duzUGvY1a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKOT1A7H8w3E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4M3_inCw8w0g"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFsvHcnm8wyG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0MT1Ph48wvc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHtFCB7v8wsx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKz01W7u8wqU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pM7ifjWy8wng"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLtCKLl08wlD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1C-xaCPWswTY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "09392626331242478f271a4cadd46a2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3bca680dff9346c8bced0aa352c372fe",
              "IPY_MODEL_f6f5eaf89a6e497b8207f368c2bd07f1",
              "IPY_MODEL_5e280d5a9dbb46c382e0ade4c35dbc5d"
            ],
            "layout": "IPY_MODEL_713caf38591440bd86dd21aa3e60639e"
          }
        },
        "0b59100373c44ea192142c3cc577cbef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0df79dd600aa4d71b7f81e3ee3026d48",
            "placeholder": "​",
            "style": "IPY_MODEL_234a2c19af8e4120a6db3b15882766e6",
            "value": "openai/o4-mini Progress: 100%"
          }
        },
        "0df79dd600aa4d71b7f81e3ee3026d48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f6370e66dd1445c97515f0430970e35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "11accb582aac4ac79e0b0f6ecaa1bd08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "234a2c19af8e4120a6db3b15882766e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24029157c43340df8d6f2e97b59a73ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ad7aa0c892e42588e95ee34d6c01331": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33fe7e53c5a64e869169b46453258057": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bca680dff9346c8bced0aa352c372fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aba6d33820d347879b34dfce16d79b4e",
            "placeholder": "​",
            "style": "IPY_MODEL_33fe7e53c5a64e869169b46453258057",
            "value": "google/gemini-flash-1.5-8b Progress: 100%"
          }
        },
        "3e24261e69f84bbeabe2d9a13f6c066f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42fd524bd71b42b6b42cc6c031a93be3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b064d3e93dd4c9ab65f96b9927e85b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f41b125e63b54b6b996d92bc26aac46a",
              "IPY_MODEL_df84ff83048c4dff9a9c26fada16fd12",
              "IPY_MODEL_568c920579dd480bb35eb86d47f5bc92"
            ],
            "layout": "IPY_MODEL_24029157c43340df8d6f2e97b59a73ec"
          }
        },
        "568c920579dd480bb35eb86d47f5bc92": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a1516a834fc4becb9fa78ab3903fc5b",
            "placeholder": "​",
            "style": "IPY_MODEL_998c8246c3fd405f8543d4db25ec5995",
            "value": " 0/419 [00:00&lt;?, ?it/s]"
          }
        },
        "5a1516a834fc4becb9fa78ab3903fc5b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e280d5a9dbb46c382e0ade4c35dbc5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7090f4f755b7445fa31c806ebcefc3bd",
            "placeholder": "​",
            "style": "IPY_MODEL_6095f69db8354709aec7496d8ddfc7f6",
            "value": " 419/419 [07:34&lt;00:00,  1.08it/s]"
          }
        },
        "6095f69db8354709aec7496d8ddfc7f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6749f9de05a54cdda6e941014745f4f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f8bb04b19964da4a01b7f61373fb612": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7090f4f755b7445fa31c806ebcefc3bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "713caf38591440bd86dd21aa3e60639e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75d700f2301f4865affb30f63c270320": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78e295b1b02f4f3eb7341c40232dc3d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "998c8246c3fd405f8543d4db25ec5995": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aba6d33820d347879b34dfce16d79b4e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb59c656ec2f47c38893cb47b2887fcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ad7aa0c892e42588e95ee34d6c01331",
            "max": 419,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_78e295b1b02f4f3eb7341c40232dc3d1",
            "value": 419
          }
        },
        "ccafd8dc61ce402a90f7ed5ec6c54033": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3ed1598c3e045918a808af55fb7c405",
            "placeholder": "​",
            "style": "IPY_MODEL_6749f9de05a54cdda6e941014745f4f7",
            "value": " 419/419 [2:24:01&lt;00:00, 15.03s/it]"
          }
        },
        "d3ed1598c3e045918a808af55fb7c405": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d631ba6949864169aea3edc4e8304283": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b59100373c44ea192142c3cc577cbef",
              "IPY_MODEL_cb59c656ec2f47c38893cb47b2887fcc",
              "IPY_MODEL_ccafd8dc61ce402a90f7ed5ec6c54033"
            ],
            "layout": "IPY_MODEL_75d700f2301f4865affb30f63c270320"
          }
        },
        "df84ff83048c4dff9a9c26fada16fd12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e24261e69f84bbeabe2d9a13f6c066f",
            "max": 419,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11accb582aac4ac79e0b0f6ecaa1bd08",
            "value": 0
          }
        },
        "eeab23cff2c64290b88514ae19eb7741": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f41b125e63b54b6b996d92bc26aac46a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eeab23cff2c64290b88514ae19eb7741",
            "placeholder": "​",
            "style": "IPY_MODEL_6f8bb04b19964da4a01b7f61373fb612",
            "value": "deepseek/deepseek-r1-0528:free Progress:   0%"
          }
        },
        "f6f5eaf89a6e497b8207f368c2bd07f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42fd524bd71b42b6b42cc6c031a93be3",
            "max": 419,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f6370e66dd1445c97515f0430970e35",
            "value": 419
          }
        },
        "f84b412da83e42968e4aedc8f064132a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5127c4e8f3774a7fb8f0f8ca32188f27",
              "IPY_MODEL_cd227b74d4774b4e9f8be80e0463ac79",
              "IPY_MODEL_3a02231d286646538781d3873432a819"
            ],
            "layout": "IPY_MODEL_d48e0548568a45698163fe1f20d8ce87"
          }
        },
        "5127c4e8f3774a7fb8f0f8ca32188f27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a77a456168a482f8e5ca160201ade7f",
            "placeholder": "​",
            "style": "IPY_MODEL_e93fa03d482243558d79e553242501d9",
            "value": "google/gemini-flash-1.5-8b Progress: 100%"
          }
        },
        "cd227b74d4774b4e9f8be80e0463ac79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48fbd03095574fbf8cd2e9abaf0544fa",
            "max": 419,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23477b5c33814675b196774a41b4353b",
            "value": 419
          }
        },
        "3a02231d286646538781d3873432a819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_706ae0c483be4967aa04a9d89c8837b7",
            "placeholder": "​",
            "style": "IPY_MODEL_f44e01386237462489d0561da307a6da",
            "value": " 419/419 [04:44&lt;00:00,  1.65it/s]"
          }
        },
        "d48e0548568a45698163fe1f20d8ce87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a77a456168a482f8e5ca160201ade7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e93fa03d482243558d79e553242501d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48fbd03095574fbf8cd2e9abaf0544fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23477b5c33814675b196774a41b4353b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "706ae0c483be4967aa04a9d89c8837b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f44e01386237462489d0561da307a6da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e6dfe8e8c894b80a7402380f0f455c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_222da82207514ef2b6f5bee48a40ed9d",
              "IPY_MODEL_b81d9d48942c41349d5f60ae65318be4",
              "IPY_MODEL_1ca1acf6992b4fe9b04eb35e377d3242"
            ],
            "layout": "IPY_MODEL_98522606ffb54763baf5d6c3ac09cad4"
          }
        },
        "222da82207514ef2b6f5bee48a40ed9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fe53fd9e658497db06e8fbeea4af497",
            "placeholder": "​",
            "style": "IPY_MODEL_133936f81bb3433295d9e72022031f8b",
            "value": "deepseek/deepseek-r1-0528:free Progress:   0%"
          }
        },
        "b81d9d48942c41349d5f60ae65318be4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11dd800626664bc48f374dbbbce24d08",
            "max": 419,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_796fdef1c4e949e9b220e1cf9fe12319",
            "value": 0
          }
        },
        "1ca1acf6992b4fe9b04eb35e377d3242": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8296749880e14621a66b4da74cd729a7",
            "placeholder": "​",
            "style": "IPY_MODEL_fdf68c28138c453383fa340be0516376",
            "value": " 0/419 [02:07&lt;?, ?it/s]"
          }
        },
        "98522606ffb54763baf5d6c3ac09cad4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fe53fd9e658497db06e8fbeea4af497": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "133936f81bb3433295d9e72022031f8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11dd800626664bc48f374dbbbce24d08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "796fdef1c4e949e9b220e1cf9fe12319": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8296749880e14621a66b4da74cd729a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdf68c28138c453383fa340be0516376": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9480b6ee734541dabdb030bf5f6e5237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c8f40c33d374fc685fb7ef0687ab061",
              "IPY_MODEL_b00d54d7154a4f3ea648c2d6168f013a",
              "IPY_MODEL_3d2fcd6ca5cc47bc902d7f56b8d321ef"
            ],
            "layout": "IPY_MODEL_60dc8edfee3c485aac82a380f7950116"
          }
        },
        "5c8f40c33d374fc685fb7ef0687ab061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b570f4a4087e4d41b8162381e3517490",
            "placeholder": "​",
            "style": "IPY_MODEL_e50ec642adf44e45b24795a94391a407",
            "value": "google/gemini-flash-1.5-8b Progress: 100%"
          }
        },
        "b00d54d7154a4f3ea648c2d6168f013a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14432a43aa6a4629b0bc584098e60dc5",
            "max": 419,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c35a7c61d0f414ba18a4dc00eef0ccf",
            "value": 419
          }
        },
        "3d2fcd6ca5cc47bc902d7f56b8d321ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f68057cf6e3f4f26a07b03b87d8b4d1c",
            "placeholder": "​",
            "style": "IPY_MODEL_e28e52799d0e4585a3c42afa38dc366f",
            "value": " 419/419 [04:23&lt;00:00,  1.72it/s]"
          }
        },
        "60dc8edfee3c485aac82a380f7950116": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b570f4a4087e4d41b8162381e3517490": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e50ec642adf44e45b24795a94391a407": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14432a43aa6a4629b0bc584098e60dc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c35a7c61d0f414ba18a4dc00eef0ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f68057cf6e3f4f26a07b03b87d8b4d1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e28e52799d0e4585a3c42afa38dc366f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b941bed380d44d079693960f6e72e0c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_56421ae887214fcba00724d28373e2e4",
              "IPY_MODEL_d1793114c2db41eebd99ca6873b21798",
              "IPY_MODEL_3a1da3b7f1d943b599af0d85e2f66519"
            ],
            "layout": "IPY_MODEL_5e1905586e474e8e8e3c2c24e3de6c79"
          }
        },
        "56421ae887214fcba00724d28373e2e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b77c814f0e02422d8e0c6560d825472e",
            "placeholder": "​",
            "style": "IPY_MODEL_226db9024e324e439753ac53adc988d1",
            "value": "openai/o4-mini Progress:   1%"
          }
        },
        "d1793114c2db41eebd99ca6873b21798": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_278f7d7a4a5f47a5984dfa222b2d68c9",
            "max": 419,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_08466ff15d3d47c087147490285e7648",
            "value": 4
          }
        },
        "3a1da3b7f1d943b599af0d85e2f66519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98677c1bcdb347eba2076a8a96162628",
            "placeholder": "​",
            "style": "IPY_MODEL_73188986e94d46d1b08d0b3ad024598b",
            "value": " 4/419 [01:48&lt;2:20:40, 20.34s/it]"
          }
        },
        "5e1905586e474e8e8e3c2c24e3de6c79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b77c814f0e02422d8e0c6560d825472e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "226db9024e324e439753ac53adc988d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "278f7d7a4a5f47a5984dfa222b2d68c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08466ff15d3d47c087147490285e7648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "98677c1bcdb347eba2076a8a96162628": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73188986e94d46d1b08d0b3ad024598b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53476cb945924e2f9fdda881b7294965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b7c0fd4ac887440aa99e983799052456",
              "IPY_MODEL_8083435822814d138c8d6699971c5db4",
              "IPY_MODEL_c3bd4cc7c7dc4886ac39168bbfc153af"
            ],
            "layout": "IPY_MODEL_ed3588f44cd64507ae3a4d26b75eaedd"
          }
        },
        "b7c0fd4ac887440aa99e983799052456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b477f2f9cf1345a2bfbd426ebbcc7b23",
            "placeholder": "​",
            "style": "IPY_MODEL_1c3f97440f8241378217fdfe29030640",
            "value": "llama3-70b-8192 Progress: 100%"
          }
        },
        "8083435822814d138c8d6699971c5db4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_febf900974f94d27a94af665bb5206a0",
            "max": 419,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_468755e6e63e44689a90452fcc50d3da",
            "value": 419
          }
        },
        "c3bd4cc7c7dc4886ac39168bbfc153af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b2ef5750ef7472bbdc19bc298db8627",
            "placeholder": "​",
            "style": "IPY_MODEL_39d833c265044a1bb28b28581462dd23",
            "value": " 419/419 [49:04&lt;00:00,  6.30s/it]"
          }
        },
        "ed3588f44cd64507ae3a4d26b75eaedd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b477f2f9cf1345a2bfbd426ebbcc7b23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c3f97440f8241378217fdfe29030640": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "febf900974f94d27a94af665bb5206a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "468755e6e63e44689a90452fcc50d3da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b2ef5750ef7472bbdc19bc298db8627": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39d833c265044a1bb28b28581462dd23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d606c677e87437091d84008f990dba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e06a539c9f2c406d848c8461166f033f",
              "IPY_MODEL_c693f813fa29465fa4ee3860d385cbd7",
              "IPY_MODEL_332b3bb8361f41b8922bc79bb895eaee"
            ],
            "layout": "IPY_MODEL_4276a90de1504948a6b6dd6380f36a1c"
          }
        },
        "e06a539c9f2c406d848c8461166f033f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fdb89d13ca64b16b27f663df783a269",
            "placeholder": "​",
            "style": "IPY_MODEL_c1a61cbdf52441f195fee31a3f5bcba7",
            "value": "llama3-70b-8192 Progress: 100%"
          }
        },
        "c693f813fa29465fa4ee3860d385cbd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f0bfdb337824551a59dd892a78f3486",
            "max": 419,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bce3da99b7a143cb84e3ed116bcb5bcb",
            "value": 419
          }
        },
        "332b3bb8361f41b8922bc79bb895eaee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4c68c3f08494338bbc0d98bc4703194",
            "placeholder": "​",
            "style": "IPY_MODEL_0d1218718ceb4ea4b8677c7e5a1e2427",
            "value": " 419/419 [01:33&lt;00:00, 10.22it/s]"
          }
        },
        "4276a90de1504948a6b6dd6380f36a1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fdb89d13ca64b16b27f663df783a269": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1a61cbdf52441f195fee31a3f5bcba7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f0bfdb337824551a59dd892a78f3486": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bce3da99b7a143cb84e3ed116bcb5bcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d4c68c3f08494338bbc0d98bc4703194": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d1218718ceb4ea4b8677c7e5a1e2427": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b2cf7cfbf3a4cc7a48632dddffcd2b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fcd296ece1d2457c8e9e6a0bdd3b0b24",
              "IPY_MODEL_a2baa90036784b588ed417e65f678cf7",
              "IPY_MODEL_22f14206f021420a8f6b6f5d47c10f85"
            ],
            "layout": "IPY_MODEL_0170831185e747c6ae2b9f2e64b855ec"
          }
        },
        "fcd296ece1d2457c8e9e6a0bdd3b0b24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bc66adbaf3e4d8ea9c165da09fb61cc",
            "placeholder": "​",
            "style": "IPY_MODEL_81899eedbd2642e38b0b54eb3fb41675",
            "value": "microsoft/mai-ds-r1:free Progress: 100%"
          }
        },
        "a2baa90036784b588ed417e65f678cf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c07e3dcfd8db44049f3d79370a5b0615",
            "max": 105,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_48d6c276b9e44f8a8c0097a8f3023362",
            "value": 105
          }
        },
        "22f14206f021420a8f6b6f5d47c10f85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6ee56e45d454f129bffdac990634f01",
            "placeholder": "​",
            "style": "IPY_MODEL_f1ef8809cdc440dbbd40858412516a09",
            "value": " 105/105 [1:12:42&lt;00:00, 28.24s/it]"
          }
        },
        "0170831185e747c6ae2b9f2e64b855ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bc66adbaf3e4d8ea9c165da09fb61cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81899eedbd2642e38b0b54eb3fb41675": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c07e3dcfd8db44049f3d79370a5b0615": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48d6c276b9e44f8a8c0097a8f3023362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d6ee56e45d454f129bffdac990634f01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1ef8809cdc440dbbd40858412516a09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c8b5f3b4bc34543b18f796fe523130e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0269a20e784e4092b59e206f2f68a283",
              "IPY_MODEL_3fdd9f1a22904ad28618aebbd3ef538d",
              "IPY_MODEL_78876ceb4f4b4c7d9b3114b4e5555c6e"
            ],
            "layout": "IPY_MODEL_c5148262e0054008ad340dac950dc78f"
          }
        },
        "0269a20e784e4092b59e206f2f68a283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7aa6a632bd0345fbbb734739aefca8cb",
            "placeholder": "​",
            "style": "IPY_MODEL_48fa334bef6a4acbba0ff2b7cfe1a6ed",
            "value": "llama3-70b-8192 Progress: 100%"
          }
        },
        "3fdd9f1a22904ad28618aebbd3ef538d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1656ce8c85fc402ea28c8abc0f8d99e9",
            "max": 210,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6913fad7b67a40bcafb1850462bc8684",
            "value": 210
          }
        },
        "78876ceb4f4b4c7d9b3114b4e5555c6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b4a7b5e0d3b4541b82f948a73b53589",
            "placeholder": "​",
            "style": "IPY_MODEL_2198a8165681490e93f8ac0aa898c552",
            "value": " 210/210 [44:17&lt;00:00, 10.43s/it]"
          }
        },
        "c5148262e0054008ad340dac950dc78f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7aa6a632bd0345fbbb734739aefca8cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48fa334bef6a4acbba0ff2b7cfe1a6ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1656ce8c85fc402ea28c8abc0f8d99e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6913fad7b67a40bcafb1850462bc8684": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b4a7b5e0d3b4541b82f948a73b53589": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2198a8165681490e93f8ac0aa898c552": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}